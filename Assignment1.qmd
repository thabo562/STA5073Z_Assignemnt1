---
title: "STA5073Z Assignment 1"
format: html
editor: visual
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE)
library(stringr)
library(dplyr)
library(tidyverse)
library(gridExtra)
library(ggplot2)

#install.packages("tidytext")
library(tidytext)

#update r and install git
#install.packages("remotes")
#remotes::install_github(sprintf("rstudio/%s",
                        #c("reticulate", "tensorflow", "keras")))
#keras:: install_keras()
library(keras)
library(tensorflow)
#tf$constant("Hello world")



```

# Abstract

Quarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see <https://quarto.org>.

\*\*index words\*\* : Bag-of_words, Tf-IDF, Feed forward neural network (FFNN), random forest, classification tree

## Introduction

The aim of this paper is to identify different machine learning models that can be used for predictive purposes, and rank them according to their ability to do so. With presidential speech from 1994 to 2022 from South African presidents, this paper will review the capacity in which classification trees , feed forward neural networks and random forests are able to accurately classify sentences to their presidents. The input structuring process will also vary between bag of words and tf-idf so as to ascertain which one is more suitable for the data at hand with a selected machine learning model.

## Exploratory Data analysis

```{r Reading in Data}

set.seed(2022)
load("F:/STA5073Z- DS4I/pre-processed assignment data.RData")
#sona<-sona[-c(2,20),]  remove Motlante and De Klerk in this version of data split
sona<-sona%>% mutate(speech= str_replace(speech, "\\d{1,2} [A-Za-z]+ \\d{4}", "")) # Remove dates at the start of the speech
sona<- sona%>% mutate(speech= str_replace(speech, pattern = "^Thursday, ", replacement = ""))# remove dates on 2 remaining Ramaphosa speeches 
sona<- sona%>% mutate(speech= str_trim(speech, side= "left"))

Sona_S_tokenized<- unnest_tokens(sona, sentence, speech, token = 'sentences') 
Sona_S_tokenized<- Sona_S_tokenized%>% mutate(sentence= str_replace_all(sentence, "[[:punct:]]", ""))


```

```{r Top 20 words}

Sona_tokenized<-unnest_tokens(sona, word, speech, token = 'words') 

Zuma<-Sona_tokenized%>% group_by(president_13, word)%>% 
        summarise("count"= n())%>% filter(president_13=="Zuma") %>%
        arrange(desc(count))%>%
        filter(!word %in% stop_words$word) %>%
        filter(rank(desc(count)) <= 15) %>%
        ggplot(aes(x = reorder(word, count), y = count)) + geom_col() + coord_flip() + xlab('Top 20 words used')+
   ggtitle("Zuma")+theme(plot.title = element_text(hjust=0.5))

Mbeki<-Sona_tokenized%>% group_by(president_13, word)%>% 
        summarise("count"= n())%>% filter(president_13=="Mbeki") %>%
        arrange(desc(count))%>%
        filter(!word %in% stop_words$word) %>%
        filter(rank(desc(count)) <= 15) %>%
        ggplot(aes(x = reorder(word, count), y = count)) + geom_col() + coord_flip() + xlab('Top 20 words used')+
   ggtitle("Mbeki")+theme(plot.title = element_text(hjust=0.5))

Mandela<-Sona_tokenized%>% group_by(president_13, word)%>% 
        summarise("count"= n())%>% filter(president_13=="Mandela") %>%
        arrange(desc(count))%>%
        filter(!word %in% stop_words$word) %>%
        filter(rank(desc(count)) <= 15) %>%
        ggplot(aes(x = reorder(word, count), y = count)) + geom_col() + coord_flip() + xlab('Top 20 words used')+
   ggtitle("Mandela")+theme(plot.title = element_text(hjust=0.5))

Ramaphosa<-Sona_tokenized%>% group_by(president_13, word)%>% 
        summarise("count"= n())%>% filter(president_13=="Ramaphosa") %>%
        arrange(desc(count))%>%
        filter(!word %in% stop_words$word) %>%
        filter(rank(desc(count)) <= 15) %>%
        ggplot(aes(x = reorder(word, count), y = count)) + geom_col() + coord_flip() + xlab('Top 20 words used')+
   ggtitle("Ramaphosa")+theme(plot.title = element_text(hjust=0.5))

DeKlerk<-Sona_tokenized%>% group_by(president_13, word)%>% 
        summarise("count"= n())%>% filter(president_13=="deKlerk") %>%
        arrange(desc(count))%>%
        filter(!word %in% stop_words$word) %>%
        filter(rank(desc(count)) <= 15) %>%
        ggplot(aes(x = reorder(word, count), y = count)) + geom_col() + coord_flip() + xlab('Top 20 words used')+
   ggtitle("deKlerk")+theme(plot.title = element_text(hjust=0.5))

Motlanthe<-Sona_tokenized%>% group_by(president_13, word)%>% 
        summarise("count"= n())%>% filter(president_13=="Motlanthe") %>%
        arrange(desc(count))%>%
        filter(!word %in% stop_words$word) %>%
        filter(rank(desc(count)) <= 15) %>%
        ggplot(aes(x = reorder(word, count), y = count)) + geom_col() + coord_flip() + xlab('Top 20 words used') + ggtitle("Motlanthe")+theme(plot.title = element_text(hjust=0.5))

#| label: fig-Words
#| fig-cap: "Top 20 words"
grid.arrange(DeKlerk,Mandela,Mbeki,Motlanthe,Zuma,Ramaphosa, ncol=3,nrow=2)
```

@fig-Words shows the most common words used by each president, outside of stop words that are common to all types of sentences construction. There is a visible tone change in the state of the nation addresses over time. With DeKlerk, a government centric tone is observed with high references to the constitution, parties and elections. The succeeding presidents put more emphasis on the betterment of the country, with Mandela and Mbeki speaking more on social welfare and Motlanthe, Zuma and Ramaphosa focusing on the country's economic development .

```{r}
#| fig-cap: "Average Sentence Length"
#| label: fig-sentences




Sona_S_tokenized %>%
  group_by(president_13) %>%
  summarise(avg_sentence_length = mean(n()))



```

## Methods

### Input Methods

#### Bag-of words

In the domain of natural language processing, Bag-of-words is a text modelling tool which allows users to discern between unnecessary information and keywords critical to the vocabulary of the model. The model

```{r}

word_bag<- Sona_tokenized%>% group_by(filename, president_13, word) %>% 
            summarise("count"=n())%>% filter(!word %in% stop_words$word)%>%
            top_n(200)

tweets_tdf<- Sona_S_tokenized %>%
  inner_join(word_bag) %>%
  group_by(filename, president_13,word) %>%
  count() %>%  
  group_by(president_13) %>%
  mutate(total = sum(n)) %>%
  ungroup()



bag_of_words <- tweets_tdf %>% 
  select(filename, president_13, word, n) %>% 
  pivot_wider(names_from = word, values_from = n, values_fill = 0)%>%
  mutate(president_13= as.factor(president_13))


test<-bag_of_words%>%semi_join(test_data, by= "filename")%>% select(-filename)
train<-bag_of_words%>%semi_join(train_data, by= "filename")%>% select(-filename)



```

#### Td-idf

### Predictive Models

#### Classification Trees

#### Random Forest

#### Neural Networks

## Results

## Discussion

## Conclusion

Potentially explore CNNs for even higher accuracy results
