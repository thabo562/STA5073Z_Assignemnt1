---
title: "Assignment 1"
author: "Thabo Dube"
date: "2023-10-02"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(stringr)
library(dplyr)
library(tidyverse)
library(rpart)
library(ggplot2)

install.packages("randomForest")
library(randomForest)

install.packages("tidytext")
library(tidytext)

#update r and install git
install.packages("remotes")
remotes::install_github(sprintf("rstudio/%s",
                        c("reticulate", "tensorflow", "keras")))
keras:: install_keras()
library(keras)
library(tensorflow)
tf$constant("Hello world")
```

```{r}
#update r and install git
install.packages("remotes")
remotes::install_github(sprintf("rstudio/%s",
                        c("reticulate", "tensorflow", "keras")))
keras:: install_keras()
library(keras)
library(tensorflow)
tf$constant("Hello world")
```


```{r Reading in Data}
set.seed(2022)
load("F:/STA5073Z- DS4I/pre-processed assignment data.RData")
#sona<-sona[-c(2,20),]  remove Motlante and De Klerk in this version of data split
sona<-sona%>% mutate(speech= str_replace(speech, "\\d{1,2} [A-Za-z]+ \\d{4}", "")) # Remove dates at the start of the speech
sona<- sona%>% mutate(speech= str_replace(speech, pattern = "^Thursday, ", replacement = ""))# remove dates on 2 remaining Ramaphosa speeches 
sona<- sona%>% mutate(speech= str_trim(speech, side= "left"))

Sona_S_tokenized<- unnest_tokens(sona, sentence, speech, token = 'sentences') 
Sona_S_tokenized<- Sona_S_tokenized%>% mutate(sentence= str_replace_all(sentence, "[[:punct:]]", ""))

```


```{r Word Visualisation}

Sona_tokenized<-unnest_tokens(sona, word, speech, token = 'words') 

Zuma<-Sona_tokenized%>% group_by(president_13, word)%>% 
        summarise("count"= n())%>% filter(president_13=="Zuma") %>%
        arrange(desc(count))%>%
        filter(!word %in% stop_words$word) %>%
        filter(rank(desc(count)) <= 20) %>%
        ggplot(aes(x = reorder(word, count), y = count)) + geom_col() + coord_flip() + xlab('Top 20 words used')+
   ggtitle("Zuma")+theme(plot.title = element_text(hjust=0.5))


Mbeki<-Sona_tokenized%>% group_by(president_13, word)%>% 
        summarise("count"= n())%>% filter(president_13=="Mbeki") %>%
        arrange(desc(count))%>%
        filter(!word %in% stop_words$word) %>%
        filter(rank(desc(count)) <= 20) %>%
        ggplot(aes(x = reorder(word, count), y = count)) + geom_col() + coord_flip() + xlab('Top 20 words used')+
   ggtitle("Mbeki")+theme(plot.title = element_text(hjust=0.5))



Mandela<-Sona_tokenized%>% group_by(president_13, word)%>% 
        summarise("count"= n())%>% filter(president_13=="Mandela") %>%
        arrange(desc(count))%>%
        filter(!word %in% stop_words$word) %>%
        filter(rank(desc(count)) <= 20) %>%
        ggplot(aes(x = reorder(word, count), y = count)) + geom_col() + coord_flip() + xlab('Top 20 words used')+
   ggtitle("Mandela")+theme(plot.title = element_text(hjust=0.5))

Ramaphosa<-Sona_tokenized%>% group_by(president_13, word)%>% 
        summarise("count"= n())%>% filter(president_13=="Ramaphosa") %>%
        arrange(desc(count))%>%
        filter(!word %in% stop_words$word) %>%
        filter(rank(desc(count)) <= 20) %>%
        ggplot(aes(x = reorder(word, count), y = count)) + geom_col() + coord_flip() + xlab('Top 20 words used')+
   ggtitle("Ramaphosa")+theme(plot.title = element_text(hjust=0.5))

```

```{r Top 20 words for each President}

par(mfrow = c(2, 2))
plot(Zuma)
plot(Mbeki)
plot(Mandela)
plot(Ramaphosa)
plot(DeKlerk)
plot(Mothlante)
```

```{r No. of Sentences per president visualisation}
# speech length
avg_Speech_length<- Sona_S_tokenized %>% group_by(filename,president_13)%>%
                      summarise("count"= n())%>%
                      group_by(president_13)%>%
                      summarise("Average" = as.integer(mean(count)))

ggplot(avg_Speech_length, aes(y=as.factor(president_13), x= Average)) + 
  geom_bar(stat = "identity") +
   scale_fill_hue(c = 40)+
  theme(legend.position="none") + 
  labs(y=" President", x= "Average no. of sentence in speeches")


```


```{r No. of words per sentence }
#sentence length

avg_Sentence_length<- Sona_S_tokenized %>% group_by(filename,president_13)%>%
                      summarise("sentence_length"=str_count(sentence, '\\w+'))%>%
                      group_by(president_13)%>%
                      summarise("Average" = as.integer(mean(sentence_length)))
                   

ggplot(avg_Sentence_length, aes(y=as.factor(president_13), x= Average)) + 
  geom_bar(stat = "identity") +
  theme(legend.position="none") + 
  labs(y=" President", x= "Average no. of words in sentences")
```

#Model Building

```{r Data Spliting}
# Because there is an uneven number of speech made by each president, the test and training are sampled proportionally to each presidents total number of speeches

test_data <- sona %>% group_by(president_13) %>% slice_sample(prop = 0.3) %>% ungroup()
train_data <- anti_join(sona, test_data, by = c("president_13", "filename"))


```


```{r Bag of words model}


word_bag<- Sona_S_tokenized%>% group_by(filename, president_13, word) %>% 
            summarise("count"=n())%>% filter(!word %in% stop_words$word)%>%
            top_n(200)

tweets_tdf<- Sona_S_tokenized %>%
  inner_join(word_bag) %>%
  group_by(filename, president_13,word) %>%
  count() %>%  
  group_by(president_13) %>%
  mutate(total = sum(n)) %>%
  ungroup()



bag_of_words <- tweets_tdf %>% 
  select(filename, president_13, word, n) %>% 
  pivot_wider(names_from = word, values_from = n, values_fill = 0)%>%
  mutate(president_13= as.factor(president_13))


test<-bag_of_words%>%semi_join(test_data, by= "filename")%>% select(-filename)
train<-bag_of_words%>%semi_join(train_data, by= "filename")%>% select(-filename)



```


```{r BOW with Classification trees}

fit <- rpart(president_13 ~ ., train, method = 'class')
# options(repr.plot.width = 12, repr.plot.height = 10) # set plot size in the notebook
plot(fit, main = 'Full Classification Tree')
text(fit, use.n = TRUE, all = TRUE)
```

```{r}
fittedtrain <- predict(fit, type = 'class')
predtrain <- table(train$president_13, fittedtrain)
predtrain

round(sum(diag(predtrain))/sum(predtrain), 3) # training accuracy

fittedtest <- predict(fit, newdata = test, type = 'class')
predtest <- table(test$president_13, fittedtest)
predtest
round(sum(diag(predtest))/sum(predtest), 3) # test accuracy
```

```{r BOW Random Forest}

install.packages("randomForest")
library(randomForest)
train<- as.data.frame(train)
classifier_RF = randomForest(x = train[,-1], 
                             y = train[,1], 
                             ntree = 100) 
  
classifier_RF #view the output of the random forest

test<- as.data.frame(test)
y_pred = predict(classifier_RF, newdata = test[,-1]) 
  
# Confusion Matrix 
confusion_mtx = table(test[,1], y_pred) 
confusion_mtx 
round(sum(diag(confusion_mtx))/sum(confusion_mtx), 3) # test accuracy

# Plotting model 
plot(classifier_RF) 
  

# Variable importance plot 
varImpPlot(classifier_RF) 
```


```{r TF-IDF}

speeches_tokens <- Sona_tokenized %>%
  count(president_13, word,filename, sort = TRUE)
 
speeches_document_frequencies <- speeches_tokens %>%
  group_by(word) %>%
  summarize(document_frequency = n_distinct(filename))

speeches_tf_idf <- speeches_tokens %>%
  left_join(speeches_document_frequencies, by = "word") %>%
  mutate(tf_idf = n * (log2(n_distinct(president_13) / document_frequency)))


```



```{r}
tfidf <- speeches_tf_idf %>% 
  select(Sent_ID,president_13, word, tf_idf) %>%  # note the change, using tf-idf
  pivot_wider(names_from = word, values_from = tf_idf, values_fill = 0)%>%
  mutate(president_13= as.factor(president_13))

```







