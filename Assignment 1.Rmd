---
title: "Assignment 1"
author: "Thabo Dube"
date: "2023-10-02"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(stringr)
library(dplyr)
library(tidyverse)
library(ggplot2)

install.packages("tidytext")
library(tidytext)

```

```{r}
#update r and install git
install.packages("remotes")
remotes::install_github(sprintf("rstudio/%s",
                        c("reticulate", "tensorflow", "keras")))
keras:: install_keras()
library(keras)
library(tensorflow)
tf$constant("Hello world")
```


```{r Reading in Data}
set.seed(2022)
load("F:/STA5073Z- DS4I/pre-processed assignment data.RData")
sona<-sona[-c(2,20),] # remove Motlante and De Klerk in this version of data split
sona<-sona%>% mutate(speech= str_replace(speech, "\\d{1,2} [A-Za-z]+ \\d{4}", "")) # Remove dates at the start of the speech
sona<- sona%>% mutate(speech= str_replace(speech, pattern = "^Thursday, ", replacement = ""))# remove dates on 2 remaining Ramaphosa speeches 
sona<- sona%>% mutate(speech= str_trim(speech, side= "left"))
sona<- sona%>% mutate(speech= str_replace_all(speech, "[[:punct:]]", ""))

```


```{r Data Visualisation}

A<-unnest_tokens(sona, word, speech, token = 'words') 

Zuma<-A%>% group_by(president_13, word)%>% 
        summarise("count"= n())%>% filter(president_13=="Zuma") %>%
        arrange(desc(count))%>%
        filter(!word %in% stop_words$word) %>%
        filter(rank(desc(count)) <= 20) %>%
        ggplot(aes(x = reorder(word, count), y = count)) + geom_col() + coord_flip() + xlab('Words used')


Mbeki<-A%>% group_by(president_13, word)%>% 
        summarise("count"= n())%>% filter(president_13=="Mbeki") %>%
        arrange(desc(count))%>%
        filter(!word %in% stop_words$word) %>%
        filter(rank(desc(count)) <= 20) %>%
        ggplot(aes(x = reorder(word, count), y = count)) + geom_col() + coord_flip() + xlab('Words used')



Mandela<-A%>% group_by(president_13, word)%>% 
        summarise("count"= n())%>% filter(president_13=="Mandela") %>%
        arrange(desc(count))%>%
        filter(!word %in% stop_words$word) %>%
        filter(rank(desc(count)) <= 20) %>%
        ggplot(aes(x = reorder(word, count), y = count)) + geom_col() + coord_flip() + xlab('Words used')

Ramaphosa<-A%>% group_by(president_13, word)%>% 
        summarise("count"= n())%>% filter(president_13=="Ramaphosa") %>%
        arrange(desc(count))%>%
        filter(!word %in% stop_words$word) %>%
        filter(rank(desc(count)) <= 20) %>%
        ggplot(aes(x = reorder(word, count), y = count)) + geom_col() + coord_flip() + xlab('Words used')

```

```{r Top 20 words for each President}

par(mfrow = c(2, 2))
plot(Zuma)
plot(Mbeki)
plot(Mandela)
plot(Ramaphosa)
```



```{r Data Spliting}
# Because there is an uneven number of speech made by each president, the test and training are sampled proportionally to each presidents total number of speeches

test_data <- sona %>% group_by(president_13) %>% slice_sample(prop = 0.3) %>% ungroup()
train_data <- anti_join(sona, test_data, by = c("president_13", "filename"))


```



```{r Tokenization}
test<-unnest_tokens(test_data, word, speech, token = 'words')
train<-unnest_tokens(train_data, word, speech, token = 'words')

```




```{r Bag of words model}
train_bag<- train%>% group_by(president_13, word) %>% 
            summarise("count"=n())%>% filter(!word %in% stop_words$word)%>%
            top_n(200, count)

```

